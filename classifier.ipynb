{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import h5py\n",
    "from scipy import io\n",
    "from scipy import signal\n",
    "import os\n",
    "import glob\n",
    "import csv\n",
    "import pywt\n",
    "from biosppy.signals import ecg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "738\n"
     ]
    }
   ],
   "source": [
    "arr = []\n",
    "with open('training2017/REFERENCE.csv', newline='') as csvfile:\n",
    "     spamreader = csv.reader(csvfile, delimiter=' ', quotechar='|')\n",
    "     for row in spamreader:\n",
    "         spam = row[0].split(',')\n",
    "         if spam[1] == 'A':\n",
    "            arr.append(spam[0])\n",
    "print (len(arr))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2952, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "l = 738 \n",
    "d = 9000\n",
    "r = 256\n",
    "data = []\n",
    "length = []\n",
    "oversampling = 2\n",
    "for i in range(l):\n",
    "    \n",
    "    db = io.loadmat('training2017/' + arr[i]) \n",
    "    for o in range(oversampling):\n",
    "        dummy = db['val'][0, :]\n",
    "        length.append(len(dummy))\n",
    "        if len(dummy) < 9000:\n",
    "            dummy = np.append(dummy, dummy)\n",
    "            dummy = np.append(dummy, dummy)\n",
    "        dummy = dummy[0:d]    \n",
    "        min = np.amin(dummy)\n",
    "        max = np.amax(dummy)    \n",
    "        ddata = np.copy((dummy-min)/(max-min))\n",
    "        ddata = signal.resample(ddata, r)\n",
    "        data.append(ddata)\n",
    "        dummy = -dummy\n",
    "        min = np.amin(dummy)\n",
    "        max = np.amax(dummy)    \n",
    "        ddata = np.copy((dummy-min)/(max-min))\n",
    "        ddata = signal.resample(ddata, r)\n",
    "        data.append(ddata)    \n",
    "data = np.asarray(data).reshape(len(data), r, 1)\n",
    "seq_in_af = np.copy(data)\n",
    "print (seq_in_af.shape)  \n",
    "#print (length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5050\n"
     ]
    }
   ],
   "source": [
    "arr = []\n",
    "with open('training2017/REFERENCE.csv', newline='') as csvfile:\n",
    "     spamreader = csv.reader(csvfile, delimiter=' ', quotechar='|')\n",
    "     for row in spamreader:\n",
    "         spam = row[0].split(',')\n",
    "         if spam[1] == 'N':\n",
    "            arr.append(spam[0])\n",
    "print (len(arr))            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10100, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "l = 5050 \n",
    "d = 9000\n",
    "r = 256\n",
    "data = []\n",
    "length = []\n",
    "for i in range(l):\n",
    "    \n",
    "    db = io.loadmat('training2017/' + arr[i]) \n",
    "    dummy = db['val'][0, :]\n",
    "    length.append(len(dummy))\n",
    "    if len(dummy) < 9000:\n",
    "        dummy = np.append(dummy, dummy)\n",
    "        dummy = np.append(dummy, dummy)\n",
    "    dummy = dummy[0:d]    \n",
    "    min = np.amin(dummy)\n",
    "    max = np.amax(dummy)    \n",
    "    ddata = np.copy((dummy-min)/(max-min))\n",
    "    ddata = signal.resample(ddata, r)\n",
    "    data.append(ddata)\n",
    "    dummy = -dummy\n",
    "    min = np.amin(dummy)\n",
    "    max = np.amax(dummy)    \n",
    "    ddata = np.copy((dummy-min)/(max-min))\n",
    "    ddata = signal.resample(ddata, r)\n",
    "    data.append(ddata)  \n",
    "data = np.asarray(data).reshape(len(data), r, 1)\n",
    "seq_in_n = np.copy(data)\n",
    "print (seq_in_n.shape)  \n",
    "#print (length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.append(np.asarray(seq_in_n), np.asarray(seq_in_af), axis=0)\n",
    "Y = np.zeros((len(seq_in_n)+len(seq_in_af)))\n",
    "Y[len(seq_in_n):] = 1\n",
    "\n",
    "idx = np.random.randint(0, len(X), size=len(X))\n",
    "X = X[idx]\n",
    "Y = Y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.layers import Input, Dense, Reshape, Dropout, LSTM, Bidirectional, ConvLSTM2D, MaxPooling1D, Conv1D, Flatten, UpSampling1D, ZeroPadding1D\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D, RepeatVector\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.utils import np_utils\n",
    "from keras.utils import plot_model\n",
    "from keras.regularizers import l1_l2\n",
    "import keras.backend as K\n",
    "from keras.models import model_from_json\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier():\n",
    "    \n",
    "    model = Sequential()           \n",
    "    model.add(LSTM(128, input_shape=(r, 1)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    optimizer = Adam(0.0002, 0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "10441/10441 [==============================] - 92s 9ms/step - loss: 0.5485 - acc: 0.7747\n",
      "Epoch 2/2\n",
      "10441/10441 [==============================] - 89s 8ms/step - loss: 0.5330 - acc: 0.7764\n",
      "2611/2611 [==============================] - 4s 2ms/step\n",
      "Model evaluation  [0.5427310835443114, 0.7694369971364086]\n",
      "Epoch 1/2\n",
      "10441/10441 [==============================] - 82s 8ms/step - loss: 0.5480 - acc: 0.7766\n",
      "Epoch 2/2\n",
      "10441/10441 [==============================] - 78s 8ms/step - loss: 0.5340 - acc: 0.7773\n",
      "2611/2611 [==============================] - 4s 2ms/step\n",
      "Model evaluation  [0.5450942354246101, 0.7656070469257613]\n",
      "Epoch 1/2\n",
      "10442/10442 [==============================] - 82s 8ms/step - loss: 0.5456 - acc: 0.7765\n",
      "Epoch 2/2\n",
      "10442/10442 [==============================] - 70s 7ms/step - loss: 0.5316 - acc: 0.7789\n",
      "2610/2610 [==============================] - 4s 1ms/step\n",
      "Model evaluation  [0.5633804176959042, 0.7593869732714248]\n",
      "Epoch 1/2\n",
      "10442/10442 [==============================] - 68s 7ms/step - loss: 0.5483 - acc: 0.7720\n",
      "Epoch 2/2\n",
      "10442/10442 [==============================] - 67s 6ms/step - loss: 0.5390 - acc: 0.7727\n",
      "2610/2610 [==============================] - 4s 2ms/step\n",
      "Model evaluation  [0.5225635532446748, 0.7839080458399893]\n",
      "Epoch 1/2\n",
      "10442/10442 [==============================] - 68s 7ms/step - loss: 0.5555 - acc: 0.7660\n",
      "Epoch 2/2\n",
      "10442/10442 [==============================] - 72s 7ms/step - loss: 0.5434 - acc: 0.7696\n",
      "2610/2610 [==============================] - 5s 2ms/step\n",
      "Model evaluation  [0.5059246920077737, 0.7965517240465829]\n"
     ]
    }
   ],
   "source": [
    "n_split = 5\n",
    "for train_index, test_index in KFold(n_split).split(X):\n",
    "    \n",
    "  x_train, x_test = X[train_index], X[test_index]\n",
    "  y_train, y_test = Y[train_index], Y[test_index]\n",
    "  model = classifier()\n",
    "  model.fit(x_train, y_train, epochs=2)\n",
    "  print('Model evaluation ', model.evaluate(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "solution:\n",
    "\n",
    "https://www.mathworks.com/help/signal/examples/classify-ecg-signals-using-long-short-term-memory-networks.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
